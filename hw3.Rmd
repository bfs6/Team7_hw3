Homework 3 - TeamName
========================================================

## `parse_lq.R`
Create a vector for each variable.

Use selector gagdet to get the html nodes of each page, read the information as text
and then get rid of the non-readable symbols and leading and tailing white spaces. 
Then select the information needed for each variable and store them in the corresponding
vector.

For the extra credit part I did amenities, guest room amenities and hotel detils.
For hotel amenities and guest room amenities, I selected the amenities features 
that looked interesting and create indicator variables: 1 if the hotel has such
amenity and 0 if it doesn't. For hotel details, I have number of floors, number 
of rooms, number of suites, check-in time and check-out time. Grab the entire list
of hotel details and store them as one vector, with the features as the names of 
vector and the elements the corresponding values. Code all missing values as NA

## `get_dennys.R`

Although the code was already created which only covered a 1000mile radius of stores, we had to change it to get information from all the Dennys in America. The way I did this was to choose 3 points on the map so that they covered all of the states aside from Alaska and Hawaii. The three points had zip codes of 64101, 89101 and 23218 which are Kansas City, Las Vegas and Richmond respectively. Then I choose zip codes in Alaska and Hawaii to get the last few states. This created 5 xml files in the data/dennys directory which I will use for parse_dennys.R

## `parse_dennys.R`
I scanned through each xml file in the directory data/dennys and then compiled an array of their addresses, city, zip code, country, latitude, longitude and UID. I also wrote a function that uses rbind to add columns of each new xml file to the dataframe using rbind. Because some of the Dennys are not located in the US, I just removed all values that are did not have the value US in the data frame under the country column. Then I deleted all the duplicates. In the end I found 1597 Dennys in the US. 



## `Task 3`


```{r}
load("data/dennys.Rdata", .GlobalEnv)
load("data/lq.Rdata", .GlobalEnv)
R = 3959

to_Radian <- function(x){
  return(x*pi/180)
}

harversine <- function(x1,y1,x2,y2){
  x1<-to_Radian(x1)
  x2<-to_Radian(x2)
  y1<-to_Radian(y1)
  y2<-to_Radian(y2)
  
  dx = x2-x1
  dy = y2-y1
  a = (sin(dx/2))^2 + cos(x1)*cos(x2)*(sin(dy/2))^2
  c = 2*atan2(sqrt(a),sqrt(1-a))
  d = R*c
  return(d)
}

dennys$longitude=as.numeric(dennys$longitude)
dennys$latitude=as.numeric(dennys$latitude)


closestdennysdistance=function(){
  
 
  lq$state<-tolower(lq$state)
  dennys$state<-tolower(dennys$state)
  lq$city<-tolower(lq$city)
  dennys$city<-tolower(dennys$city)
  
  c=vector()
  for (i in seq_along(lq$location_name)){
    mindist=9999999
    dennysubset=dennys[which(abs(dennys$longitude-lq$longitude[i])<2) ,]
    dennysubset2=dennysubset[which(abs(dennysubset$latitude-lq$latitude[i])<2),]
    if (length(dennysubset2$uid)==0){
      c=c(c, 138)
    }
    else{
    for(j in seq_along(dennysubset2$uid)){
      
      x1=as.numeric(lq$latitude[i])
      x2=as.numeric(lq$longitude[i])
      y1=as.numeric(dennysubset2$latitude[j])
      y2=as.numeric(dennysubset2$longitude[j])
      temp=harversine(x1,x2,y1,y2) 
      if (temp<=mindist){
        mindist=temp
      }
      
      
    }
    c=c(c, mindist)
    }
  }
  return(c[!is.na(c)])
}

howmanylaquinta=function(n){
  k=closestdennysdistance()
  count=0
  for (i in 1:length(k)){
    if (k[i]<=n){
      count=count+1
    }
  }
  return(count)
  
}

#print
k=closestdennysdistance()


xlab=c(0.2,0.5,1,2,3,4,5)
ylab=vector()
for(i in 1:length(xlab)){
  ylab=c(ylab, howmanylaquinta(xlab[i]))
}
```

## `Task 3`
 To verify Hedbergs claim, we decided to look at all Laquinta locations and observe the distance of the nearest Dennys to each Laquinta. My code iterated through all Laquinta locations using a for-loop. Then I had a nested for-loop that iterated through all Dennys in a 138 mile by 138 mile (Harversine=2) square plot of land centered around the specific Laquinta. I implemented my iterator this way becuase reducing the Dennys dataframe into a subset would decrease run time as it significant reduces the size of the nested for- loop. The only issue would be that dennys outside of the subset would not register a distance but I replaced those distances with 138 miles. Then I  computed the distance of the closest Dennys to the specific Laquinta. My computation was derived from the Harversine equation which took in 4 arguments of the laquintas and the dennys latitudes and longitudes to compute a distance in miles. 

After I computed a list of the closest Dennys to each Laquinta, I found that the mean distance between all Laquintas to their closest Dennys is 11.90 miles with a standard deviation of 20.54. This seems to refute Hedbergs claim since 11.90 miles is quite a long distance however we noticed that the relatively high standard deviation probably indicates the presence of outliers. A check on the median shows us that half of the Dennys are within 3. 18 miles of a Laquinta, thus favoring Hedbergs claim.

```{r}
print(mean(k))
print(sd(k))
print(median(k))

```

Therefore we created a histogram to show the percentages of Laquintas that have a Dennys within a certain distance of x miles. 
Here is our results:

```{r}
barplot(ylab/length(lq$address), names.arg=xlab,ylab="percent" ,main="Percentage of Laquintas with Dennys within x miles ", 
        xlab="miles")


```

```{r}
table <- as.table(ylab)
rownames(table)=xlab
print(table)
```
Clearly 60% or 530 of the 878 Laquintas have a Dennys within 5 miles thus it clearly supports Hedbergs claim. 
Furthermore a cumulative plot shows that most Laquintas are located witin 10 miles of a Dennys
```{r}
j=ecdf(k)
plot(j, xlab = 'Distance between Laquinta and Dennys', ylab = '', main = 'Empirical Cumluative Distribution of distance')
abline(v=10)
```